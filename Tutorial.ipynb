{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-louvain==0.5\n",
    "#!pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "\n",
    "from operator import itemgetter\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"quakers_nodelist.csv\",\"r\") as nodecsv:\n",
    "    nodereader = csv.reader(nodecsv)\n",
    "    #retrieve data using Python list comprehension\n",
    "    nodes = [n for n in nodereader][1:]\n",
    "    \n",
    "node_names = [n[0] for n in nodes]\n",
    "\n",
    "with open(\"quakers_edgelist.csv\", \"r\" ) as edgecsv:\n",
    "    edgereader = csv.reader(edgecsv)\n",
    "    edges = [tuple(e) for e in edgereader][1:] #retrieve the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print(len(node_names))\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Neworkx: Create graph \n",
    "\n",
    "<p> \n",
    "Now you have your data as two Python lists: a list of nodes (node_names) and a list of edges (edges). In NetworkX, you can put these two lists together into a single network object that understands how nodes and edges are related. This object is called a Graph, referring to one of the common terms for data organized as a network [n.b. it does not refer to any visual representation of the data. Graph here is used purely in a mathematical, network analysis sense.] First you must initialize a Graph object with the following command:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "G = nx.Graph() #creates empty graph\n",
    "\n",
    "#Add list of nodes and edges\n",
    "G.add_nodes_from(node_names)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 119\n",
      "Number of edges: 174\n",
      "Average degree:   2.9244\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding attributes\n",
    "\n",
    "<p> For NetworkX, a Graph object is one big thing (your network) made up of two kinds of smaller things (your nodes and your edges). So far you’ve uploaded nodes and edges (as pairs of nodes), but NetworkX allows you to add attributes to both nodes and edges, providing more information about each of them. Later on in this tutorial, you’ll be running metrics and adding some of the results back to the Graph as attributes. For now, let’s make sure your Graph contains all of the attributes that are currently in our CSV.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "You’ll want to return to a list you created at the beginning of your script: nodes. This list contains all of the rows from quakers_nodelist.csv, including columns for name, historical significance, gender, birth year, death year, and SDFB ID. You’ll want to loop through this list and add this information to our graph. There are a couple ways to do this, but NetworkX provides two convenient functions for adding attributes to all of a Graph’s nodes or edges at once: nx.set_node_attributes() and nx.set_edge_attributes(). To use these functions, you’ll need your attribute data to be in the form of a Python dictionary, in which node names are the keys and the attributes you want to add are the values.5 You’ll want to create a dictionary for each one of your attributes, and then add them using the functions above. The first thing you must do is create five empty dictionaries, using curly braces:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_sig_dict = {}\n",
    "gender_dict = {}\n",
    "birth_dict = {}\n",
    "death_dict = {}\n",
    "id_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now we can loop through our nodes list and add the appropriate items to each dictionary. We do this by knowing in advance the position, or index, of each attribute. Because our quaker_nodelist.csv file is well-organized, we know that the person’s name will always be the first item in the list: index 0, since you always start counting with 0 in Python. The person’s historical significance will be index 1, their gender will be index 2, and so on. Therefore we can construct our dictionaries like so </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    hist_sig_dict[node[0]] = node[1]\n",
    "    gender_dict[node[0]] = node[2]\n",
    "    birth_dict[node[0]] = node[3]\n",
    "    death_dict[node[0]] = node[4]\n",
    "    id_dict[node[0]] = node[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now you have a set of dictionaries that you can use to add attributes to nodes in your Graph object. The set_node_attributes function takes three variables: the Graph to which you’re adding the attribute, the dictionary of id-attribute pairs, and the name of the new attribute. The code for adding your six attributes looks like this:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, hist_sig_dict, 'historical_significance')\n",
    "nx.set_node_attributes(G, gender_dict, 'gender')\n",
    "nx.set_node_attributes(G, birth_dict, 'birth_year')\n",
    "nx.set_node_attributes(G, death_dict, 'death_year')\n",
    "nx.set_node_attributes(G, id_dict, 'sdfb_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Now all of your nodes have these six attributes, and you can access them at any time. For example, you can print out all the birth years of your nodes by looping through them and accessing the birth_year attribute, like this:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph Wyeth 1663\n",
      "Alexander Skene of Newtyle 1621\n",
      "James Logan 1674\n",
      "Dorcas Erbery 1656\n",
      "Lilias Skene 1626\n",
      "William Mucklow 1630\n",
      "Thomas Salthouse 1630\n",
      "William Dewsbury 1621\n",
      "John Audland 1630\n",
      "Richard Claridge 1649\n",
      "William Bradford 1663\n",
      "Fettiplace Bellers 1687\n",
      "John Bellers 1654\n",
      "Isabel Yeamans 1637\n",
      "George Fox the younger 1551\n",
      "George Fox 1624\n",
      "John Stubbs 1618\n",
      "Anne Camm 1627\n",
      "John Camm 1605\n",
      "Thomas Camm 1640\n",
      "Katharine Evans 1618\n",
      "Lydia Lancaster 1683\n",
      "Samuel Clarridge 1631\n",
      "Thomas Lower 1633\n",
      "Gervase Benson 1569\n",
      "Stephen Crisp 1628\n",
      "James Claypoole 1634\n",
      "Thomas Holme 1626\n",
      "John Freame 1665\n",
      "John Swinton 1620\n",
      "William Mead 1627\n",
      "Henry Pickworth 1673\n",
      "John Crook 1616\n",
      "Gilbert Latey 1626\n",
      "Ellis Hookes 1635\n",
      "Joseph Besse 1683\n",
      "James Nayler 1618\n",
      "Elizabeth Hooten 1562\n",
      "George Whitehead 1637\n",
      "John Whitehead 1630\n",
      "William Crouch 1628\n",
      "Benjamin Furly 1636\n",
      "Silvanus Bevan 1691\n",
      "Robert Rich 1607\n",
      "John Whiting 1656\n",
      "Christopher Taylor 1614\n",
      "Thomas Lawson 1630\n",
      "Richard Farnworth 1630\n",
      "William Coddington 1601\n",
      "Thomas Taylor 1617\n",
      "Richard Vickris 1590\n",
      "Robert Barclay 1648\n",
      "Jane Sowle 1631\n",
      "Tace Sowle 1666\n",
      "Leonard Fell 1624\n",
      "Margaret Fell 1614\n",
      "George Bishop 1558\n",
      "Elizabeth Leavens 1555\n",
      "Thomas Curtis 1602\n",
      "Alice Curwen 1619\n",
      "Alexander Parker 1628\n",
      "John Wilkinson 1652\n",
      "Thomas Aldam 1616\n",
      "David Barclay of Ury 1610\n",
      "David Barclay 1682\n",
      "Sir Charles Wager 1666\n",
      "George Keith 1638\n",
      "James Parnel 1636\n",
      "Peter Collinson 1694\n",
      "Franciscus Mercurius van Helmont 1614\n",
      "William Caton 1636\n",
      "Francis Howgill 1618\n",
      "Richard Hubberthorne 1628\n",
      "William Ames 1552\n",
      "William Rogers 1601\n",
      "Isaac Norris 1671\n",
      "Anthony Sharp 1643\n",
      "Mary Fisher 1623\n",
      "Anne Conway Viscountess Conway and Killultagh 1631\n",
      "Samuel Fisher 1604\n",
      "Francis Bugg 1640\n",
      "Sarah Gibbons 1634\n",
      "William Tomlinson 1650\n",
      "Humphrey Norton 1655\n",
      "William Gibson 1628\n",
      "Gideon Wanton 1693\n",
      "John Wanton 1672\n",
      "Grace Chamber 1676\n",
      "Mary Prince 1569\n",
      "John Bartram 1699\n",
      "Edward Haistwell 1658\n",
      "John ap John 1625\n",
      "John Rous 1585\n",
      "Anthony Pearson 1627\n",
      "Solomon Eccles 1617\n",
      "John Burnyeat 1631\n",
      "Edward Burrough 1633\n",
      "Rebecca Travers 1609\n",
      "William Edmundson 1627\n",
      "Sarah Cheevers 1608\n",
      "Edward Pyott 1560\n",
      "Daniel Quare 1648\n",
      "John Penington 1655\n",
      "Mary Penington 1623\n",
      "Charles Marshall 1637\n",
      "Humphrey Woolrich 1633\n",
      "William Penn 1644\n",
      "Mary Pennyman 1630\n",
      "Dorothy Waugh 1636\n",
      "David Lloyd 1656\n",
      "Lewis Morris 1671\n",
      "Martha Simmonds 1624\n",
      "John Story 1571\n",
      "Thomas Story 1670\n",
      "Thomas Ellwood 1639\n",
      "William Simpson 1627\n",
      "Samuel Bownas 1677\n",
      "John Perrot 1555\n",
      "Hannah Stranger 1656\n"
     ]
    }
   ],
   "source": [
    "for n in G.nodes():\n",
    "    print(n, G.node[n]['birth_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics available in NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network density: 0.02478279447372169\n"
     ]
    }
   ],
   "source": [
    "density = nx.density(G)\n",
    "print(\"Network density:\", density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = nx.connected_components(G)\n",
    "largest_component = max(components, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network diameter of largest component: 8\n"
     ]
    }
   ],
   "source": [
    "subgraph = G.subgraph(largest_component)\n",
    "diameter = nx.diameter(subgraph)\n",
    "print(\"Network diameter of largest component:\", diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = dict(G.degree(G.nodes()))\n",
    "nx.set_node_attributes(G, degree_dict, 'degree')\n",
    "sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 nodes by degree:\n",
      "('George Fox', 22)\n",
      "('William Penn', 18)\n",
      "('James Nayler', 16)\n",
      "('George Whitehead', 13)\n",
      "('Margaret Fell', 13)\n",
      "('Benjamin Furly', 10)\n",
      "('Edward Burrough', 9)\n",
      "('George Keith', 8)\n",
      "('Thomas Ellwood', 8)\n",
      "('Francis Howgill', 7)\n",
      "('John Perrot', 7)\n",
      "('John Audland', 6)\n",
      "('Richard Farnworth', 6)\n",
      "('Alexander Parker', 6)\n",
      "('John Story', 6)\n",
      "('John Stubbs', 5)\n",
      "('Thomas Curtis', 5)\n",
      "('John Wilkinson', 5)\n",
      "('William Caton', 5)\n",
      "('Anthony Pearson', 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 20 nodes by degree:\")\n",
    "for d in sorted_degree[:20]:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betweenness_dict = nx.betweenness_centrality(G) # Run betweenness centrality\n",
    "eigenvector_dict = nx.eigenvector_centrality(G) # Run eigenvector centrality\n",
    "\n",
    "# Assign each to an attribute in your network\n",
    "nx.set_node_attributes(G, betweenness_dict, 'betweenness')\n",
    "nx.set_node_attributes(G, eigenvector_dict, 'eigenvector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 nodes by betweenness centrality:\n",
      "('William Penn', 0.23999456006192205)\n",
      "('George Fox', 0.23683257726065216)\n",
      "('George Whitehead', 0.12632024847366005)\n",
      "('Margaret Fell', 0.12106792237170329)\n",
      "('James Nayler', 0.10446026280446098)\n",
      "('Benjamin Furly', 0.06419626175167242)\n",
      "('Thomas Ellwood', 0.046190623885104545)\n",
      "('George Keith', 0.045006564009171565)\n",
      "('John Audland', 0.04164936340077581)\n",
      "('Alexander Parker', 0.03893676140525336)\n",
      "('John Story', 0.028990098622866983)\n",
      "('John Burnyeat', 0.028974117533439564)\n",
      "('John Perrot', 0.02829566854990583)\n",
      "('James Logan', 0.026944806605823553)\n",
      "('Richard Claridge', 0.026944806605823553)\n",
      "('Robert Barclay', 0.026944806605823553)\n",
      "('Elizabeth Leavens', 0.026944806605823553)\n",
      "('Thomas Curtis', 0.026729751729751724)\n",
      "('John Stubbs', 0.024316593960227152)\n",
      "('Mary Penington', 0.02420824624214454)\n"
     ]
    }
   ],
   "source": [
    "sorted_betweenness = sorted(betweenness_dict.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "print(\"Top 20 nodes by betweenness centrality:\")\n",
    "for b in sorted_betweenness[:20]:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: William Penn | Betweenness Centrality: 0.23999456006192205 | Degree: 18\n",
      "Name: George Fox | Betweenness Centrality: 0.23683257726065216 | Degree: 22\n",
      "Name: George Whitehead | Betweenness Centrality: 0.12632024847366005 | Degree: 13\n",
      "Name: Margaret Fell | Betweenness Centrality: 0.12106792237170329 | Degree: 13\n",
      "Name: James Nayler | Betweenness Centrality: 0.10446026280446098 | Degree: 16\n",
      "Name: Benjamin Furly | Betweenness Centrality: 0.06419626175167242 | Degree: 10\n",
      "Name: Thomas Ellwood | Betweenness Centrality: 0.046190623885104545 | Degree: 8\n",
      "Name: George Keith | Betweenness Centrality: 0.045006564009171565 | Degree: 8\n",
      "Name: John Audland | Betweenness Centrality: 0.04164936340077581 | Degree: 6\n",
      "Name: Alexander Parker | Betweenness Centrality: 0.03893676140525336 | Degree: 6\n",
      "Name: John Story | Betweenness Centrality: 0.028990098622866983 | Degree: 6\n",
      "Name: John Burnyeat | Betweenness Centrality: 0.028974117533439564 | Degree: 4\n",
      "Name: John Perrot | Betweenness Centrality: 0.02829566854990583 | Degree: 7\n",
      "Name: James Logan | Betweenness Centrality: 0.026944806605823553 | Degree: 4\n",
      "Name: Richard Claridge | Betweenness Centrality: 0.026944806605823553 | Degree: 2\n",
      "Name: Robert Barclay | Betweenness Centrality: 0.026944806605823553 | Degree: 3\n",
      "Name: Elizabeth Leavens | Betweenness Centrality: 0.026944806605823553 | Degree: 2\n",
      "Name: Thomas Curtis | Betweenness Centrality: 0.026729751729751724 | Degree: 5\n",
      "Name: John Stubbs | Betweenness Centrality: 0.024316593960227152 | Degree: 5\n",
      "Name: Mary Penington | Betweenness Centrality: 0.02420824624214454 | Degree: 4\n"
     ]
    }
   ],
   "source": [
    "#First get the top 20 nodes by betweenness as a list\n",
    "top_betweenness = sorted_betweenness[:20]\n",
    "\n",
    "#Then find and print their degree\n",
    "for tb in top_betweenness: # Loop through top_betweenness\n",
    "    degree = degree_dict[tb[0]] # Use degree_dict to access a node's degree, see footnote 2\n",
    "    print(\"Name:\", tb[0], \"| Betweenness Centrality:\", tb[1], \"| Degree:\", degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced NetworkX: Community detection with modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U python-louvain\n",
    "communities = community.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, communities, 'modularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity Class 0 Sorted by Eigenvector Centrality:\n",
      "Name: Thomas Ellwood | Eigenvector Centrality: 0.17608142535843857\n",
      "Name: Mary Penington | Eigenvector Centrality: 0.0682675324207553\n",
      "Name: William Rogers | Eigenvector Centrality: 0.0578926617015966\n",
      "Name: Thomas Curtis | Eigenvector Centrality: 0.04644778567046172\n",
      "Name: Joseph Wyeth | Eigenvector Centrality: 0.023938569252885733\n"
     ]
    }
   ],
   "source": [
    "# First get a list of just the nodes in that class\n",
    "class0 = [n for n in G.nodes() if G.node[n]['modularity'] == 0]\n",
    "\n",
    "# Then create a dictionary of the eigenvector centralities of those nodes\n",
    "class0_eigenvector = {n:G.node[n]['eigenvector'] for n in class0}\n",
    "\n",
    "# Then sort that dictionary and print the first 5 results\n",
    "class0_sorted_by_eigenvector = sorted(class0_eigenvector.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "print(\"Modularity Class 0 Sorted by Eigenvector Centrality:\")\n",
    "for node in class0_sorted_by_eigenvector[:5]:\n",
    "    print(\"Name:\", node[0], \"| Eigenvector Centrality:\", node[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: ['Joseph Wyeth', 'Thomas Curtis', 'William Rogers', 'John Penington', 'Mary Penington', 'Thomas Ellwood', 'William Simpson']\n",
      "Class 2: ['James Logan', 'Richard Claridge', 'William Bradford', 'Isabel Yeamans', 'Samuel Clarridge', 'James Claypoole', 'Joseph Besse', 'Jane Sowle', 'Tace Sowle', 'Peter Collinson', 'Isaac Norris', 'Anthony Sharp', 'John Bartram', 'Edward Haistwell', 'John ap John', 'John Burnyeat', 'William Edmundson', 'William Penn', 'David Lloyd', 'Thomas Story', 'Samuel Bownas']\n",
      "Class 3: ['Dorcas Erbery', 'Gervase Benson', 'James Nayler', 'William Crouch', 'Robert Rich', 'Richard Farnworth', 'Thomas Aldam', 'Francis Howgill', 'William Tomlinson', 'Anthony Pearson', 'Martha Simmonds', 'Hannah Stranger']\n",
      "Class 4: ['William Mucklow', 'William Dewsbury', 'George Fox', 'John Crook', 'Ellis Hookes', 'Elizabeth Hooten', 'William Coddington', 'Leonard Fell', 'Mary Fisher', 'Mary Prince', 'Edward Burrough', 'John Perrot']\n",
      "Class 5: ['Thomas Salthouse', 'George Fox the younger', 'Thomas Lower', 'Thomas Holme', 'William Mead', 'Thomas Lawson', 'Margaret Fell', 'Elizabeth Leavens', 'Alexander Parker', 'Sir Charles Wager', 'William Gibson', 'Lewis Morris']\n",
      "Class 6: ['John Audland', 'Anne Camm', 'John Camm', 'Thomas Camm', 'John Wilkinson', 'Solomon Eccles', 'Edward Pyott', 'Charles Marshall', 'John Story']\n",
      "Class 8: ['John Stubbs', 'Stephen Crisp', 'John Swinton', 'Benjamin Furly', 'Robert Barclay', 'David Barclay of Ury', 'George Keith', 'James Parnel', 'Franciscus Mercurius van Helmont', 'William Caton', 'William Ames', 'Anne Conway Viscountess Conway and Killultagh', 'Samuel Fisher']\n",
      "Class 12: ['Henry Pickworth', 'Gilbert Latey', 'George Whitehead', 'John Whitehead', 'Silvanus Bevan', 'Alice Curwen', 'Richard Hubberthorne', 'Francis Bugg', 'Rebecca Travers', 'Daniel Quare']\n",
      "Class 13: ['John Whiting', 'Christopher Taylor', 'Thomas Taylor']\n"
     ]
    }
   ],
   "source": [
    "modularity = {} # Create a new, empty dictionary\n",
    "for k,v in communities.items(): # Loop through the community dictionary\n",
    "    if v not in modularity:\n",
    "        modularity[v] = [k] # Add a new key for a modularity class the code hasn't seen before\n",
    "    else:\n",
    "        modularity[v].append(k) # Append a name to the list for a modularity class the code has already seen\n",
    "\n",
    "for k,v in modularity.items(): # Loop through the new dictionary\n",
    "    if len(v) > 2: # Filter out modularity classes with 2 or fewer nodes\n",
    "        print('Class '+str(k)+':', v) # Print out the classes and their members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(G, 'quaker_network.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
